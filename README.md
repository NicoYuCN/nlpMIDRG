# nlpMIDRG

    To address the anisotropic distribution of token representation \\
when fine-tuning pre-trained large languge models (LLMs) for downstream application tasks, 
we proposed a hybrid CLpCEwDCS decoding framework (contrastive learning penalized cross-entropy with diveristy contrastive search decoding). The novelty comes from 
